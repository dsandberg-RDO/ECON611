{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f9107fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec52bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tuber': 'in ag context, this is the potato while underground.',\n",
       " 'lifter': 'used in potato harvest, the equipment that digs tubers.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict ={\n",
    "    \"tuber\": \"in ag context, this is the potato while underground.\",\n",
    "    \"lifter\": \"used in potato harvest, the equipment that digs tubers.\"\n",
    "}\n",
    "\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "417764bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tuber': {}, 'lifter': {}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\n",
    "    \"tuber\":{},\n",
    "    \"lifter\": {}\n",
    "}\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa61c549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tuber': {'spud': 'slang for a potato',\n",
       "  'tater': 'typically smashed, a vehicle for garlic and butter'},\n",
       " 'lifter': {'spud': 'a high school Olympic Weightlifting athlete',\n",
       "  'tater': 'completion of a heavy lift'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict ={\n",
    "    \"tuber\": {\"spud\": \"slang for a potato\",\n",
    "             \"tater\": \"typically smashed, a vehicle for garlic and butter\"},\n",
    "    \"lifter\": {\"spud\": \"a high school Olympic Weightlifting athlete\",\n",
    "               \"tater\": \"completion of a heavy lift\"}\n",
    "}\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b78800fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tuber</th>\n",
       "      <th>lifter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spud</th>\n",
       "      <td>slang for a potato</td>\n",
       "      <td>a high school Olympic Weightlifting athlete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tater</th>\n",
       "      <td>typically smashed, a vehicle for garlic and bu...</td>\n",
       "      <td>completion of a heavy lift</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tuber  \\\n",
       "spud                                  slang for a potato   \n",
       "tater  typically smashed, a vehicle for garlic and bu...   \n",
       "\n",
       "                                            lifter  \n",
       "spud   a high school Olympic Weightlifting athlete  \n",
       "tater                   completion of a heavy lift  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53f81ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_dict = {\n",
    "    \"person\": {\n",
    "        \"name\":\"Drew Sandberg\",\n",
    "        \"coursework\": \"Master of Science in Business Analytics\",\n",
    "        \"motivation\": \"Resolve imposter syndrome; Stay relevant as an analyst/data scientist; Earn promotion\",\n",
    "        \"futurePlans\": \"Promotion to Data Scientist\\nBuild a Data Science community in FM area\\nStart businesses in Otter Tail County\"\n",
    "    }\n",
    "}\n",
    "\n",
    "hw_dict_df = pd.DataFrame(hw_dict)\n",
    "hw_dict_df\n",
    "hw_dict_df.to_csv(\"DrewSandbergInfo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ef9128b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-92255c44e47c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;31m# add columns to df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m \u001b[0minfluencer_dict_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Expertise\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Bio\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Website\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Social Media\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;31m# write df to csv.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    778\u001b[0m             )\n\u001b[0;32m    779\u001b[0m         \u001b[1;31m# fall back to Int64Index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__floordiv__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4305\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4307\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4308\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4309\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "influencer_dict = {\n",
    "    \"Name\":{},\n",
    "    \"Expertise\": {},\n",
    "    \"Bio\": {},\n",
    "    \"Website\": {},\n",
    "    \"Social Media\": {}\n",
    "}\n",
    "\n",
    "influencer_dict_df = pd.DataFrame(influencer_dict)\n",
    "\n",
    "hanselman = np.array([\n",
    "    \"Scott Hanselman\",\n",
    "    \"Software developer and technologist\",\n",
    "    \"Scott has been a developer for 30 years and has been blogging at https://hanselman.com for 20 years! He works in Open Source on .NET and the Azure Cloud for Microsoft out of his home office in Portland, Oregon.\",\n",
    "    \"https://www.hanselman.com/\",\n",
    "    \"Twitter: @shanselman\"\n",
    "])\n",
    "\n",
    "BFG = ([\n",
    "    \"Billy F. Gibbons\",\n",
    "    \"Musician\",\n",
    "    \"Primary vocalist and lead guitar for ZZ Top\",\n",
    "    \"https://billygibbons.com/\",\n",
    "    \"Twitter: @BillyFGibbons\"\n",
    "])\n",
    "\n",
    "Arnold = np.array([\n",
    "    \"Arnold Schwartenegger\",\n",
    "    \"Former Governor of California.\",\n",
    "    \"Austrian-American actor, producer, businessman, retired bodybuilder, and former politician who served as the 38th governor of California from 2003 to 2011.\",\n",
    "    \"http://schwarzenegger.com/\",\n",
    "    \"Twitter: @Schwarzenegger\"\n",
    "])\n",
    "\n",
    "JLB = np.array([\n",
    "    \"James Lee Burke\",\n",
    "    \"Fiction Writer\",\n",
    "    \"James Lee Burke is a New York Times bestselling author, two-time winner of the Edgar Award, and the recipient of the Guggenheim Fellowship for Creative Arts in Fiction. He’s authored thirty-nine novels and two short story collections.\",\n",
    "    \"https://www.jamesleeburke.com/\",\n",
    "    \"Twitter: @JamesLeeBurke\"\n",
    "])\n",
    "\n",
    "dRob = np.array([\n",
    "    \"David Robinson\",\n",
    "    \"Data Scientist. Author.\",\n",
    "    \"David G. Robinson is a data scientist at the Heap analytics company. He is a co-author of the tidytext R (programming language) package and the O’Reilly book, Text Mining with R. Robinson has previously worked as a Chief Data Scientist at DataCamp and as a data scientist at Stack Overflow.[1] He was also a data engineer at Flatiron Health in 2019.\",\n",
    "    \"http://varianceexplained.org/\",\n",
    "    \"Github: https://github.com/dgrtwo; Twitter: @drob\"\n",
    "])\n",
    "\n",
    "andrew = np.array([\n",
    "    \"Andrew Couch\",\n",
    "    \"R and Data Science\",\n",
    "    \"Data Scientist and University of Iowa grad. Posts screencast videos to YouTube. Data and R enthusiast.\",\n",
    "    \"https://www.linkedin.com/in/andrew-couch/\",\n",
    "    \"No social\"\n",
    "])\n",
    "\n",
    "hadley = np.array([\n",
    "    \"Hadley Wickham\",\n",
    "    \"Data Scientist. Author. Professor.\",\n",
    "    \"Chief Scientist at RStudio; adjuct professor at Univ. of Auckland, Stanford University, and Rice University\",\n",
    "    \"http://hadley.nz\",\n",
    "    \"Twitter: @hadleywickham\"\n",
    "])\n",
    "\n",
    "baxter = np.array([\n",
    "    \"Baxter Black\",\n",
    "    \"Poet. Veterinarian. Cowboy Philosopher.\",\n",
    "    \"Baxter Black is a cowboy poet, former large animal veterinarian and entertainer of the agricultural masses. \",\n",
    "    \"https://baxter-black.merchmadeeasy.com/\",\n",
    "    \"Twitter: @BaxterBlack\"\n",
    "])\n",
    "\n",
    "buck = np.array([\n",
    "    \"Buck Woody\",\n",
    "    \"Applied Data Scientist\",\n",
    "    \"Buck Woody is an Applied Data Scientist working on the Azure Data Services team at Microsoft, and uses data and technology to solve business and science problems. With over 39 years of professional and practical experience in computer technology, he is also a popular speaker at conferences around the world.\",\n",
    "    \"https://www.linkedin.com/in/buckwoody/\",\n",
    "    \"Twitter: @BuckWoodyMSFT\"\n",
    "])\n",
    "\n",
    "julia = np.array([\n",
    "    \"Julia Silge\",\n",
    "    \"Software Engineer and Data Scientist\",\n",
    "    \"Data scientist and software engineer at RStudio working on open source modeling tools. Studied physics and astronomy with a PhD in 2005\",\n",
    "    \"https://juliasilge.com/\",\n",
    "    \"Twitter: @juliasilge\"\n",
    "])\n",
    "\n",
    "# arrays to df\n",
    "influencer_dict_df = pd.DataFrame(data=[hanselman, BFG, Arnold, JLB, dRob, andrew, hadley, baxter, buck, julia])\n",
    "\n",
    "# add columns to df\n",
    "influencer_dict_df.columns[\"Name\", \"Expertise\", \"Bio\", \"Website\", \"Social Media\"]\n",
    "\n",
    "# write df to csv.\n",
    "influencer_dict_df.to_csv(\"DrewSandbergInfluencers.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ef642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
