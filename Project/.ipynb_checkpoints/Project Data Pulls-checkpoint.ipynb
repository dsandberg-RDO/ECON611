{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbad5191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import json\n",
    "import pandas_datareader as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87389e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yahoo_stock_pull(year, dict_, filename):\n",
    "    start = datetime.datetime(year, 1, 1)\n",
    "    end = datetime.datetime.today()\n",
    "    keys = dict_.keys()\n",
    "    new_dict={}\n",
    "    for key in keys:\n",
    "        new_dict[key] = web.DataReader(key, 'yahoo', start, end)\n",
    "    df = pd.concat([df['Close'] for df in new_dict.values()], axis=1, keys=new_dict.keys())\n",
    "    df.columns = df.columns.map(dict_)\n",
    "    df.to_csv(filename)\n",
    "    return\n",
    "\n",
    "def fed_data_pull(year, dict_, filename):\n",
    "    start = datetime.datetime(year, 1, 1)\n",
    "    end = datetime.datetime.today()\n",
    "    keys = dict_.keys()\n",
    "    df = web.DataReader(keys,'fred', start, end)\n",
    "    df.columns = df.columns.map(dict_)\n",
    "    df.to_csv(filename)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d6bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_assets = {\n",
    "    'WSHOMCB':'Fed-held Mortgage-backed Securities',\n",
    "    'RESPPANWW':'Fed Total Assets',\n",
    "    'CURRCIR': \"Currency in Circulation (Billions)\"\n",
    "}\n",
    "filename = 'Federal Reserve Assets.csv'\n",
    "fed_data_pull(2015, fed_assets, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9954ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "money_circ = {\n",
    "    'CURRCIR': \"USD in Circulation (Billions)\"\n",
    "}\n",
    "filename = \"US Currency in Circulation.csv\"\n",
    "fed_data_pull(2001, money_circ, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2be3849",
   "metadata": {},
   "outputs": [],
   "source": [
    "steel_production_dict = {\n",
    "    'IPN3311A2RS': 'Industrial Production of Steel for Durable Goods',\n",
    "    'IPG333S': 'Industrial Production of Machinery'\n",
    "}\n",
    "filename = 'Production.csv'\n",
    "fed_data_pull(2015, steel_production_dict, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0edcf746",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_dict = {\n",
    "    'DE':'John Deere',\n",
    "    'CNHI':'CNH Intl',\n",
    "    'AGCO':'AGCO',\n",
    "    'TWI':'Tital-Intl',\n",
    "    'LNN':'Lindasy Corp',\n",
    "    'ALG':'Alamo Group'\n",
    "}\n",
    "filename = 'Ag Mfg Stock Close.csv'\n",
    "yahoo_stock_pull(2015, stock_dict, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5176c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "steel_dict = {\n",
    "    'CLF':'Cleveland Cliffs Inc',\n",
    "    'NUE':'Nucor Corp',\n",
    "    'STLD':'Steel Dynamics',\n",
    "    'TMST':'TimkenSteel Corp',\n",
    "    'RYI':'Ryerson Holding Corp'\n",
    "}\n",
    "\n",
    "filename = 'Steel.csv'\n",
    "yahoo_stock_pull(2015, steel_dict, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ace838",
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_dict = {\n",
    "    'WPS012202':   'Corn',\n",
    "    'WPU01830131': 'Soybeans',\n",
    "    'WPU0121':     'Wheat',\n",
    "    'WPU011306':   'Potatoes'\n",
    "}\n",
    "\n",
    "filename = 'Commodity PPI.csv'\n",
    "fed_data_pull(2015, commodity_dict, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e015521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "breakeven_dict = {'T5YIE': '5 YR Break-even',\n",
    "                  'T7YIEM': '7 YR Break-even',\n",
    "                  'T10YIEM': '10 YR Break-even', \n",
    "                  'T20YIEM': '20 YR Break-even', \n",
    "                  'T30YIEM': '30 YR Break-even'}\n",
    "\n",
    "filename ='Breakeven Rates.csv'\n",
    "fed_data_pull(2000, breakeven_dict, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "318b5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "metals_dict = {\n",
    "    'PALUMUSDM':'Global Alumuminum $USD Per Metic Ton', \n",
    "    'WPU101707':'Cold-Rolled Steel PPI', \n",
    "    'WPU10260301':'Electronic Wire and Cable PPI', \n",
    "    'WPU101703': 'Hot-Rolled Steel PPI'\n",
    "}\n",
    "\n",
    "filename = 'Metals.csv'\n",
    "fed_data_pull(2000, metals_dict, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82bbb7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "equip_dict = {\n",
    "    \"WPU11140911\":\"Ag Equipment Parts\",\n",
    "    'WPU11140611': 'Ag Harvest Equip.',\n",
    "    'WPU11140711': 'Haying Equipment',\n",
    "    'WPU11140511': 'Planting/Fertizer Equip.',\n",
    "    'WPU11140211': 'Ag Attachments'\n",
    "}\n",
    "filename = 'Equipment PPI.csv'\n",
    "fed_data_pull(2015, equip_dict, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feade5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_dict = {\n",
    "    'CES3100000003':'Avg Hourly Wage Durable Good Mfg.',\n",
    "    'JTS3200QUL':'Job Quits (x1000) Durable Goods Mfg',\n",
    "    'JTS3200HIL':'Job Hires (x1000) Durable Goods Mfg',\n",
    "    'JTS3200JOL':'Job Openings (x1000) Durable Good Mfg',\n",
    "    'CIVPART': 'Civilian Labor Participation Rate',\n",
    "    'CLF16OV':'Civilian Labor Population (x1000)'\n",
    "}\n",
    "filename = 'Employment.csv'\n",
    "fed_data_pull(2015, employment_dict, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55b9c60b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'NationalFile.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12760/3881973318.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnational_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NationalFile.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnational_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnational_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnational_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FEATURE_CLASS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Populated Place'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnational_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnational_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FEATURE_NAME'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'STATE_ALPHA'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PRIM_LAT_DEC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PRIM_LONG_DEC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'STATE_NUMERIC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'COUNTY_NUMERIC'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnational_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'any'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'NationalFile.csv'"
     ]
    }
   ],
   "source": [
    "# national_df = pd.read_csv('NationalFile.csv')\n",
    "# national_df = national_df[national_df['FEATURE_CLASS']=='Populated Place']\n",
    "# national_df = national_df[['FEATURE_NAME', 'STATE_ALPHA', 'PRIM_LAT_DEC', 'PRIM_LONG_DEC', 'STATE_NUMERIC', 'COUNTY_NUMERIC']]\n",
    "\n",
    "# national_df.dropna(how='any', axis=0, inplace=True)\n",
    "# national_df['FIPS'] = national_df['STATE_NUMERIC'].astype(int) * 1000 + national_df['COUNTY_NUMERIC'].astype(int)\n",
    "# national_df['CityState'] = national_df['FEATURE_NAME'].str.title() + ' ' + national_df['STATE_ALPHA']\n",
    "\n",
    "# # Reduce the file down to the necessary columns\n",
    "# national_df = national_df[['CityState', 'FIPS', 'PRIM_LAT_DEC', 'PRIM_LONG_DEC']]\n",
    "# national_df.rename(columns={'PRIM_LAT_DEC':'Latitude', 'PRIM_LONG_DEC':'Longitude'}, inplace=True)\n",
    "\n",
    "# # Write the file to repo; will import later.\n",
    "# national_df.to_csv('CityState.csv', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498ab51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
